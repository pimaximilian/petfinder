{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e159cbd5-b691-43b2-bc54-203de22f5990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import warnings\n",
    "import os, json, cv2, random\n",
    "from PIL import Image, ImageOps\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from multiprocessing import Pool\n",
    "from tqdm import notebook\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6622b312-7e81-44ac-8cd6-190fb548c6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mypath=\"train\"\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88161ce9-1ff2-48a7-ac31-f2031b64e618",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PetfinderPrep(object):\n",
    "    def __init__(self):\n",
    "        self.predictor = None\n",
    "        self.cfg = None\n",
    "        self.path = \"train\"\n",
    "        self.save_path = \"prep\"\n",
    "        self.load_model()\n",
    "        self.class_labels = [15, 16, 17]\n",
    "        pass\n",
    "    \n",
    "    def to_PIL(self, img_cv2):\n",
    "        img_cv2 = cv2.cvtColor(img_cv2, cv2.COLOR_BGR2RGB)\n",
    "        return Image.fromarray(img_cv2)\n",
    "    \n",
    "    def load_model(self):\n",
    "        cfg = get_cfg()\n",
    "        cfg.MODEL.DEVICE='cpu'\n",
    "        # add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
    "        cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "        cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
    "        # Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
    "        cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "        self.predictor = DefaultPredictor(cfg)\n",
    "        self.cfg = cfg\n",
    "        \n",
    "    def predict(self, img):\n",
    "        return self.predictor(img)\n",
    "    \n",
    "    def is_mask(self, masks, j, i, relevant_masks):\n",
    "        for x in range(len(masks)):\n",
    "            if x in relevant_masks:\n",
    "                if masks[x][j][i] == True:\n",
    "                    return True\n",
    "        return False\n",
    "    \n",
    "    def relevant_masks(self, pred_classes, class_labels=None):\n",
    "        if class_labels is None:\n",
    "            class_labels = self.class_labels\n",
    "        relevant_masks = []\n",
    "        for i, itm in enumerate(pred_classes):\n",
    "            if itm in class_labels:\n",
    "                relevant_masks.append(i)\n",
    "        return relevant_masks\n",
    "    \n",
    "    def delete_background(self, img):\n",
    "        outputs = self.predict(img)\n",
    "        if len(outputs[\"instances\"].pred_classes) < 1:\n",
    "            warnings.warn(\"NO CLASSES FOUND\")\n",
    "        rm = self.relevant_masks(outputs[\"instances\"].pred_classes, self.class_labels)\n",
    "        mask = outputs[\"instances\"].pred_masks\n",
    "        i = len(mask[0][0])\n",
    "        j = len(mask[0])\n",
    "        test = img.copy()\n",
    "        for j1 in range(j):\n",
    "            for i1 in range(i):\n",
    "                if not self.is_mask(mask, j1, i1, rm):\n",
    "                      test[j1,i1] = 255\n",
    "        return test\n",
    "    \n",
    "    def resize_img(self, img, size=(1280, 1280), fill=(255, 255, 255)):\n",
    "        img_white = self.delete_background(img)\n",
    "        img_rs = self.to_PIL(img_white)\n",
    "        img_rs = self.resize_with_padding(img_rs, size, fill)\n",
    "        return img_rs\n",
    "\n",
    "\n",
    "    def resize_with_padding(self, img, expected_size, fill):\n",
    "        img.thumbnail((expected_size[0], expected_size[1]))\n",
    "        delta_width = expected_size[0] - img.size[0]\n",
    "        delta_height = expected_size[1] - img.size[1]\n",
    "        pad_width = delta_width // 2\n",
    "        pad_height = delta_height // 2\n",
    "        padding = (pad_width, pad_height, delta_width - pad_width, delta_height - pad_height)\n",
    "        return ImageOps.expand(img, padding, fill=fill)\n",
    "    \n",
    "    def viz(self, img, outputs):\n",
    "        v = Visualizer(img[:, :, ::-1], MetadataCatalog.get(self.cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "        out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "        return self.to_PIL(out.get_image()[:, :, ::-1])\n",
    "    \n",
    "    def wrapper(self, image):\n",
    "        img = cv2.imread(image)\n",
    "        out = self.predict(img)\n",
    "        viz = self.viz(img, out)\n",
    "        return self.to_PIL(img), self.resize_img(img), viz, out\n",
    "    \n",
    "    def prep_img(self, image, save=True):\n",
    "        img = cv2.imread(f\"{self.path}/{image}\")\n",
    "        img_rs = self.resize_img(img)\n",
    "        if save:\n",
    "            img_rs.save(f\"{self.save_path}/{image}\")\n",
    "        return img_rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a83c4fb-4695-4e4e-baaf-9c44423b7dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images(images):\n",
    "    pp = PetfinderPrep()\n",
    "    for image in images:\n",
    "        pp.prep_img(image)\n",
    "        \n",
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "225841e2-b4c3-470b-9070-13d48bedda47",
   "metadata": {},
   "outputs": [],
   "source": [
    "ch = list(chunks(onlyfiles,500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f421966-fd4a-4874-a7c0-40505257090c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mproposal_generator.anchor_generator.cell_anchors.{0, 1, 2, 3, 4}\u001b[0m\n",
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mproposal_generator.anchor_generator.cell_anchors.{0, 1, 2, 3, 4}\u001b[0m\n",
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mproposal_generator.anchor_generator.cell_anchors.{0, 1, 2, 3, 4}\u001b[0m\n",
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mproposal_generator.anchor_generator.cell_anchors.{0, 1, 2, 3, 4}\u001b[0m\n",
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mproposal_generator.anchor_generator.cell_anchors.{0, 1, 2, 3, 4}\u001b[0m\n",
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mproposal_generator.anchor_generator.cell_anchors.{0, 1, 2, 3, 4}\u001b[0m\n",
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mproposal_generator.anchor_generator.cell_anchors.{0, 1, 2, 3, 4}\u001b[0m\n",
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mproposal_generator.anchor_generator.cell_anchors.{0, 1, 2, 3, 4}\u001b[0m\n",
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mproposal_generator.anchor_generator.cell_anchors.{0, 1, 2, 3, 4}\u001b[0m\n",
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mproposal_generator.anchor_generator.cell_anchors.{0, 1, 2, 3, 4}\u001b[0m\n",
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mproposal_generator.anchor_generator.cell_anchors.{0, 1, 2, 3, 4}\u001b[0m\n",
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mproposal_generator.anchor_generator.cell_anchors.{0, 1, 2, 3, 4}\u001b[0m\n",
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mproposal_generator.anchor_generator.cell_anchors.{0, 1, 2, 3, 4}\u001b[0m\n",
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mproposal_generator.anchor_generator.cell_anchors.{0, 1, 2, 3, 4}\u001b[0m\n",
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mproposal_generator.anchor_generator.cell_anchors.{0, 1, 2, 3, 4}\u001b[0m\n",
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mproposal_generator.anchor_generator.cell_anchors.{0, 1, 2, 3, 4}\u001b[0m\n",
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mproposal_generator.anchor_generator.cell_anchors.{0, 1, 2, 3, 4}\u001b[0m\n",
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mproposal_generator.anchor_generator.cell_anchors.{0, 1, 2, 3, 4}\u001b[0m\n",
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mproposal_generator.anchor_generator.cell_anchors.{0, 1, 2, 3, 4}\u001b[0m\n",
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mproposal_generator.anchor_generator.cell_anchors.{0, 1, 2, 3, 4}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "with Pool() as p:\n",
    "    p.map(process_images, ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e8f6ca54-6927-4a33-8c39-76cbb8c65f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mproposal_generator.anchor_generator.cell_anchors.{0, 1, 2, 3, 4}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pp = PetfinderPrep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fdfb20-087e-4011-91fa-8b4867f537c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.prep_img(\"6285b27404f2b2bf3df0ecaecc5c8b89.jpg\")\n",
    "org, resz, viz, out = pp.wrapper(f\"train/6285b27404f2b2bf3df0ecaecc5c8b89.jpg\")\n",
    "resz.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6b692582-c1b1-4753-b662-79885df5134b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8149b23596ab40f39f3fc672fee91771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22142/4153125793.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"train/{file}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mpp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"prep/{file}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_22142/2091260324.py\u001b[0m in \u001b[0;36mresize_img\u001b[0;34m(self, img, size, fill)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mresize_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mimg_white\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete_background\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mimg_rs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_PIL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_white\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mimg_rs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_with_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_rs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_22142/2091260324.py\u001b[0m in \u001b[0;36mdelete_background\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m                       \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_22142/2091260324.py\u001b[0m in \u001b[0;36mis_mask\u001b[0;34m(self, masks, j, i, relevant_masks)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrelevant_masks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for file in notebook.tqdm(onlyfiles):\n",
    "    image = f\"train/{file}\"\n",
    "    img = cv2.imread(image)\n",
    "    pp.resize_img(img).save(f\"prep/{file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5ffb0d22-c5dd-4db7-b07e-cf50e3627083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 1500)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image.open(f\"prep/{file}\").size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9e449820-ff70-443b-bb8f-54f46c9d579c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53f92b4dca964c43a13919e09244d020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wl=[]\n",
    "hl=[]\n",
    "for file in notebook.tqdm(onlyfiles):\n",
    "    w,h = Image.open(f\"train/{file}\").size\n",
    "    wl.append(w)\n",
    "    hl.append(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ec63915f-6672-4636-bcbd-f1bc2ee4ab4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1280"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(wl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fbb108ba-1b41-45f8-8186-7b4712e1ac35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1280"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(hl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d715c1f-09c3-43af-b844-f63706576046",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-9.m80",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m80"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
